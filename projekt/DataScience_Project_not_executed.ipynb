{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Linus Tech Tips Forum Cinebench Ergebnisse (Max Hammer, 5.12.2021)\n",
    "\n",
    "#### Project Summary\n",
    "1.1. Perform EDA for the provided data\n",
    "\n",
    "a. Perform EDA\n",
    "\n",
    "b. Compute the Pearson correlation coefficient. Which conclusion can you make?\n",
    "\n",
    "1.2. Linear regression\n",
    "\n",
    "a. Define linear function for your analysis. That is, f=ai+b, where a is the slope and b is the intercept. So find the best fit line using np.polyfit().\n",
    "\n",
    "b. Plot the data and the best fit line. Print out the slope and intercept. (Think: what are their units?)\n",
    "\n",
    "1.3. How is it optimal?\n",
    "\n",
    "a. The function np.polyfit() that you used to get your regression parameters finds the optimal slope and intercept. It is optimizing the sum of the squares of the residuals, also known as RSS (for residual sum of squares). Plot the function that is being optimized, the RSS, versus the slope parameter a. To do this, fix the intercept to be what you found in the optimization. Then, plot the RSS vs. the slope. Where is it minimal? What does it mean for the research?\n",
    "\n",
    "1.4. Pairs bootstrap or permutation?\n",
    "\n",
    "a. Perform pairs bootstrap or permutation to plot a histogram describing the estimate of the slope from the data. Also report the 95% confidence interval of the slope.\n",
    "\n",
    "1.5. Plotting bootstrap or permutation regressions\n",
    "\n",
    "a. A nice way to visualize the variability we might expect in a linear regression is to plot the line you would get from each replicate of the slope and intercept. Do this for the first 100 of your replicates of the slope and intercept\n",
    "\n",
    "1.6. Hypothesis test on Pearson correlation\n",
    "\n",
    "a. Formulate Hypothesis and Test it. Provide a conclusion for it\n",
    "\n",
    "1.7. Provide the conclusion of your clock speed research. Is it possible to perfume here A/B Test? What it can show? What confidence intervals and p-values show us in regard to testing of Null-hypothesis?\n",
    "\n",
    "1.8. What shows us a Bonferroni test? Use: https://www.investopedia.com/terms/b/bonferroni-test.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import re\n",
    "import unittest\n",
    "import datetime\n",
    "from scipy import optimize\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Describe and Gather Data \n",
    "First dataset are the results of the Linus Tech Tips forum cinebench results, gathered from https://linustechtips.com/topic/62476-post-your-cinebench-r2015r1152003-scores-dont-read-the-op-plz/\n",
    "\n",
    "Second dataset is the cpu db from techpowerup (https://www.techpowerup.com/cpu-specs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "multithread_data = pd.read_csv(\"Linus tech tips Cinebench R15 scores - CPU muti thread.csv\")\n",
    "singlethread_data = pd.read_csv(\"Linus tech tips Cinebench R15 scores - CPU single thread.csv\")\n",
    "\n",
    "cpu_data = pd.read_csv(\"cpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "multithread_data = multithread_data.drop([\"Name\", \"extra info\"], axis=1)\n",
    "singlethread_data = singlethread_data.drop([\"Name\", \"Extra Info\"], axis=1)\n",
    "cpu_data = cpu_data.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the names from the ltt forum to the name format from techpowerup\n",
    "def map_intel_name(name):\n",
    "  template = \"Core {}-{}\"\n",
    "  split = name.split(' ')\n",
    "  return template.format(split[2].lower(), split[3])\n",
    "\n",
    "def multiprocessor_remove(name):\n",
    "  return name.split('x ')[1]\n",
    "\n",
    "def remove_amd(name):\n",
    "  return name.split('AMD ')[1]\n",
    "\n",
    "def remove_intel(name):\n",
    "  return name.split('Intel ')[1]\n",
    "\n",
    "def format_epy(name):\n",
    "  return \"EPYC {}\".format(name.split('Epyc ')[1])\n",
    "\n",
    "def map_name(name):\n",
    "  intel_core = re.compile('Intel Core I\\d')\n",
    "  multiprocessor = re.compile('^\\dx')\n",
    "  amd = re.compile('^AMD')\n",
    "  intel = re.compile('^Intel')\n",
    "  epys = re.compile('^Epyc')\n",
    "  if intel_core.match(name):\n",
    "    return map_intel_name(name)\n",
    "  if multiprocessor.match(name):\n",
    "    name = multiprocessor_remove(name)\n",
    "  if amd.match(name):\n",
    "    name = remove_amd(name)\n",
    "  if intel.match(name):\n",
    "    name = remove_intel(name)\n",
    "  return name\n",
    "\n",
    "print(map_name(\"Intel Core I9 9900K\"))\n",
    "print(map_name(\"Ryzen Threadripper 1950X\"))\n",
    "\n",
    "multithread_data['CPU'] = multithread_data['CPU'].map(map_name)\n",
    "singlethread_data['CPU'] = singlethread_data['CPU'].map(map_name)\n",
    "\n",
    "print(multithread_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize clocks on cou base stats\n",
    "def remove_MHz(clk):\n",
    "  num = pd.to_numeric(clk.split(' MHz')[0])\n",
    "  return num / 1000\n",
    "\n",
    "def remove_GHz(clk):\n",
    "  return pd.to_numeric(clk.split('GHz')[0])\n",
    "\n",
    "def map_clk_speed(clk):\n",
    "  mhz_regex = re.compile('^\\d{3,} MHz$')\n",
    "  if mhz_regex.match(clk):\n",
    "    return remove_MHz(clk)\n",
    "  return remove_GHz(clk)\n",
    "\n",
    "cpu_data['minclock'] = cpu_data['minclock'].map(map_clk_speed)\n",
    "cpu_data['maxclock'] = cpu_data['maxclock'].map(map_clk_speed)\n",
    "\n",
    "cpu_data['cores'] = pd.to_numeric(cpu_data['cores'])\n",
    "cpu_data['threads'] = pd.to_numeric(cpu_data['threads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ghz from clock speed on ltt dataset\n",
    "def remove_ghz(clk):\n",
    "  return clk.split('ghz')[0]\n",
    "\n",
    "multithread_data['Clock Speed'] = pd.to_numeric(multithread_data['Clock Speed'].map(remove_ghz))\n",
    "singlethread_data['Clock Speed'] = pd.to_numeric(singlethread_data['Clock Speed'].map(remove_ghz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only year from release date\n",
    "def extract_year(date):\n",
    "  split = date.split(' ')\n",
    "  return pd.to_numeric(split[-1])\n",
    "\n",
    "cpu_data['release'] = cpu_data['release'].map(extract_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chosen that model\n",
    "\n",
    "#### 3.2 Hypothesis Tests\n",
    "provide needed statistiks with explonation and answer to your business questions for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Overclock Dataset\n",
    "overclock_data = pd.DataFrame()\n",
    "\n",
    "for idx,row in multithread_data.iterrows():\n",
    "  base_entry = cpu_data[cpu_data['name'] == row['CPU']]\n",
    "  if base_entry.empty:\n",
    "    continue\n",
    "  new_entry = {'cpu':row['CPU'], 'cores':base_entry['cores'].values[0],'threads':base_entry['threads'].values[0], 'base_clk':base_entry['minclock'].values[0], 'boost_clk':base_entry['maxclock'].values[0], 'oc_clk':row['Clock Speed'], 'release':base_entry['release'].values[0]}\n",
    "  \n",
    "  if idx == 0:\n",
    "    overclock_data = pd.DataFrame.from_dict(new_entry)\n",
    "  else:\n",
    "    overclock_data = overclock_data.append(new_entry, ignore_index=True)\n",
    "\n",
    "overclock_data = overclock_data.assign(oc_diff=lambda x: x['oc_clk'] - x['base_clk'])\n",
    "overclock_data = overclock_data.assign(oc_boost_diff=lambda x: x['oc_clk'] - x['boost_clk'])\n",
    "overclock_data = overclock_data.sort_values(by=[\"release\"])\n",
    "overclock_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the dataset\n",
    "\n",
    "cpu: name of the processor<br>\n",
    "cores: the amount of physical cores the cpu has<br>\n",
    "threads: the amount of logical threads a cpu has (usually cores*2)<br>\n",
    "base_clk: the base clock speed of the cpu as specified by the manufacturer<br>\n",
    "boost_clk: the maximum boost clock speed of the cpu as specified by the manufacturer<br>\n",
    "oc_clk: the achieved overclocked clock speeds of the cpu<br>\n",
    "release: the year in which the cpu was released<br>\n",
    "oc_diff: oc_clk - base_clk<br>\n",
    "oc_boost_diff: oc_clk - boost_clk<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA\n",
    "mean_oc_diff = np.mean(overclock_data.oc_diff)\n",
    "median_oc_diff = np.mean(overclock_data.oc_diff)\n",
    "std_dev_oc_diff = np.std(overclock_data.oc_diff)\n",
    "\n",
    "mean_oc_boost_diff = np.mean(overclock_data.oc_boost_diff)\n",
    "median_oc_boost_diff = np.mean(overclock_data.oc_boost_diff)\n",
    "std_dev_oc_boost_diff = np.std(overclock_data.oc_boost_diff)\n",
    "\n",
    "print('Mean of oc clock difference to base clock: {}GHz'.format(mean_oc_diff))\n",
    "print('Median of oc clock difference to base clock: {}GHz'.format(median_oc_diff))\n",
    "print('Standard deviation oc vs base clock difference: ', std_dev_oc_diff)\n",
    "\n",
    "print('Mean of oc clock difference to boost clock: {}GHz'.format(mean_oc_boost_diff))\n",
    "print('Median of oc clock difference to boost clock: {}GHz'.format(median_oc_boost_diff))\n",
    "print('Standard deviation oc vs boost clock difference: ', std_dev_oc_boost_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show outliers\n",
    "print('Outliers_min',overclock_data.oc_diff.min())\n",
    "print('Outliers_max',overclock_data.oc_diff.max())\n",
    "\n",
    "print('Outliers_min_boost',overclock_data.oc_boost_diff.min())\n",
    "print('Outliers_max_boost',overclock_data.oc_boost_diff.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Show your solution: the Model of  Data and any conclutions \n",
    "#### 4.1 Create graphics, any needed queris to visualise your solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot per year oc results\n",
    "release_years = overclock_data['release'].unique()\n",
    "release_years.sort()\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.title('Boxplot of overclock base clock differences')\n",
    "for year in release_years:\n",
    "  plt.boxplot(overclock_data[overclock_data['release'] == year]['oc_diff'], positions=[year])\n",
    "plt.ylabel('GHz over base clock')\n",
    "plt.xlabel('Year of processor release')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.title('Boxplot of overclock to boost clock differences')\n",
    "for year in release_years:\n",
    "  plt.boxplot(overclock_data[overclock_data['release'] == year]['oc_boost_diff'], positions=[year])\n",
    "plt.ylabel('GHz over boost clock')\n",
    "plt.xlabel('Year of processor release')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result interpretation\n",
    "The difference in outliers, when comparing the plots for base clock and boost clock, is mainly due to the nature of Intel's boost especially on many core processors. \n",
    "\n",
    "As an example the i9-9900K:\n",
    "  Intel advertises a boost clock ofa 5GHz, but only for a load of up to 2 cores.<br>\n",
    "  For any load of up to 4 cores, the processor's boost clock is lowered, down to 4.8GHz.<br>\n",
    "  Finally the boost clock for a load of 6 and more cores, the boost clock is 4.7GHz\n",
    "\n",
    "The data used for overclock results is about a multi core test and the many core processors are not capable of running their top boost clock on all of their cores. Even in an overclocked state. The later plot shows many outliers on the low end of the chart, these would be bad performing 7th generation high end desktop chips from Intelm like the i9 7980XE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of base clock in relation to boost clock, using the mean\n",
    "base_clocks = []\n",
    "boost_clocks = []\n",
    "oc_clocks = []\n",
    "for year in release_years:\n",
    "  base_clocks.append(overclock_data[overclock_data['release'] == year]['base_clk'].mean())\n",
    "  boost_clocks.append(overclock_data[overclock_data['release'] == year]['boost_clk'].mean())\n",
    "  oc_clocks.append(overclock_data[overclock_data['release'] == year]['oc_clk'].mean())\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(release_years,base_clocks, label='base clocks')\n",
    "plt.plot(release_years,boost_clocks, label='boost clocks')\n",
    "plt.plot(release_years, oc_clocks, label='avg overclocked clocks')\n",
    "plt.xticks(release_years)\n",
    "plt.ylabel('Clock speed in GHz')\n",
    "plt.xlabel('Years of processor release')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result interpretation\n",
    "This shows the trend towards more cores, which cannot sustain a high base clock due to the required power and therefore required cooling. But the graph shows at the same time, that the clock speeds for single or dual core loads continue to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_diff = []\n",
    "boost_diff = []\n",
    "for year in release_years:\n",
    "  base_diff.append(overclock_data[overclock_data['release'] == year]['oc_diff'].mean())\n",
    "  boost_diff.append(overclock_data[overclock_data['release'] == year]['oc_boost_diff'].mean())\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(release_years,base_diff, label='difference in base and oc clock')\n",
    "plt.plot(release_years,boost_diff, label='difference in boost and oc clock')\n",
    "plt.xticks(release_years)\n",
    "plt.ylabel('Clock speed difference in GHz')\n",
    "plt.xlabel('Years of processor release')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result interpretation\n",
    "\n",
    "The graph shows that, while the difference in base clock and oc clock are relatively stable, the difference between the maximum  boost clocks and the achieved overclocked results are very small.\n",
    "\n",
    "This shows a trend in the development of CPUs, that the manufacturers are pushing for the highest possible clock speeds and therefore highest possible performance. Due to thermal or power limitations, these maximum clock speeds, are not used for loads of more than 2 cores. The overclocking results, therefore show that the advertised boost clock speeds can be achieved in an all core load and aren't the ceiling. The graph also shows, that the headroom for overclocking is already very slim on modern chips. \n",
    "\n",
    "Due to the overclocking dataset being during an all-core load and the CPU stat dataset showing maximum boost, which (most of the time) gives a frequency for at most 2 cores, it would also be feasable to conclude, that newer CPUs are difficult to overclock further than their advertised maximum boost clock.\n",
    "\n",
    "Although the difference between boost and overclocked speeds seem to be very low, the workload for the overclocked results is for all cores, the CPU has access to. The advertised boost clocks, which the CPU stat dataset has is only applicable to at, most 2 cores. This means, although the results don't look like it, there is still overclocking done, because the frequency of all cores is different, than the advertised frequency for a load with the amount of cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression for oc_diff and oc_boost_diff with release year\n",
    "\n",
    "def linear_regression(x,y):\n",
    "  return np.polynomial.Polynomial.fit(x,y,1).convert().coef\n",
    "\n",
    "# perform linear regression function\n",
    "def perform_linear_regression(x,y,xlabel,ylabel,title):\n",
    "  # Calculate the linear regression and output the slope and interception\n",
    "  intercept, slope = linear_regression(x, y)\n",
    "  print(slope, intercept)\n",
    "\n",
    "  # Plot the data\n",
    "  plt.plot(x, slope * x + intercept, color=\"red\")\n",
    "  plt.plot(x, y, marker='o', linestyle='none')\n",
    "  plt.xlabel(xlabel)\n",
    "  plt.ylabel(ylabel)\n",
    "  plt.title(title, fontsize=16)\n",
    "  plt.tight_layout()\n",
    "  plt.ticklabel_format(useOffset=False, style='plain')\n",
    "  plt.margins(0.01)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "x = overclock_data[\"release\"]\n",
    "y = overclock_data[\"oc_diff\"]\n",
    "yboost = overclock_data[\"oc_boost_diff\"]\n",
    "\n",
    "perform_linear_regression(x, yboost, \"release year\", \"difference of oc speed and boost speed\", 'Relationship of release year and the difference of oc clock and boost clock with linear regression')\n",
    "\n",
    "perform_linear_regression(x, y, \"release year\", \"difference of oc speed and base speed\", 'Relationship of release year and the difference of oc clock and base clock with linear regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_rss(x, y, slope, intercept, title=\"\"):\n",
    "\n",
    "  def residualSumOfSquares(x, y, slope, intercept):\n",
    "    return np.sum((y - (intercept + slope * x))**2)\n",
    "\n",
    "  # Calculate the rss function value for the slope.\n",
    "  slopeY = residualSumOfSquares(x, y, slope, intercept)\n",
    "\n",
    "\n",
    "  def rssParabolaWithInvertedMimimum(i):\n",
    "    # First: move the rss function on the y axis to zero and then 10 Percent of this way more into the negative direction.\n",
    "    # Second: Mirror the negative part (minimum of the function) on the x axis in the positive direction.\n",
    "    return abs(residualSumOfSquares(x, y, i, intercept) - slopeY * 1.1)\n",
    "\n",
    "\n",
    "  def findMinimum(f, start):\n",
    "    # Optimize the function using a given start point\n",
    "    optimationResult = optimize.minimize(f, x0=start, method='Powell')\n",
    "\n",
    "    # Check if the optimization was successful.\n",
    "    if (not optimationResult.success):\n",
    "      raise Exception(f'No minimum found for {f.__name__} with x0={start}')\n",
    "\n",
    "    # Return the x value of the found minimum.\n",
    "    return optimationResult.x[0]\n",
    "\n",
    "\n",
    "  def findLeftAndRightMimima(f, start):\n",
    "    # Get the left and right minimum.\n",
    "    leftMinimum = findMinimum(f, start - 1)\n",
    "    rightMinimum = findMinimum(f, start + 1)\n",
    "\n",
    "    return (leftMinimum, rightMinimum)\n",
    "\n",
    "  # Get the right and left minimum starting from the slope on the rss function with inverted minimum.\n",
    "  leftMinimum, rightMinimum = findLeftAndRightMimima(rssParabolaWithInvertedMimimum, slope)\n",
    "\n",
    "  print(\"leftMinimum\", leftMinimum, \"rightMinimum\", rightMinimum)\n",
    "\n",
    "  # Calculate the distance of both minima\n",
    "  delta = abs(rightMinimum - leftMinimum)\n",
    "  \n",
    "  xStart = slope - delta\n",
    "  xEnd = slope + delta\n",
    "  # Get evenly spreaded points (the slope values) between the start and end point\n",
    "  xValues = np.linspace(xStart, xEnd, 200)\n",
    "  \n",
    "  rssValues = np.empty_like(xValues)\n",
    "\n",
    "  # Calculate the rss function values for the given slopes\n",
    "  for i, slope_at_i in enumerate(xValues):\n",
    "    rssValues[i] = residualSumOfSquares(x, y, slope_at_i, intercept)\n",
    "  \n",
    "  plt.plot(xValues, rssValues)\n",
    "  plt.xlabel('slope')\n",
    "  plt.ylabel('residuals sum of square')\n",
    "  plt.title('Slope vs Residuals Sum Of Square ' + title)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# Perform rss test for oc_diff\n",
    "slope, intercept = linear_regression(x,y)\n",
    "\n",
    "test_with_rss(x, y, slope, intercept, title=\"base clocks\")\n",
    "\n",
    "# Perform rss test for oc_boost_diff\n",
    "slope, intercept = linear_regression(x,yboost)\n",
    "\n",
    "test_with_rss(x, yboost, slope, intercept, title=\"boost clocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs bootstrap or permutation\n",
    "\n",
    "def perform_bootstrapping(x, y, title=\"\"):\n",
    "\n",
    "  def pairBootstrap(x, y, size=1, percentage=1):\n",
    "\n",
    "    inds = np.arange(len(x))\n",
    "\n",
    "    slopes = np.empty(size)\n",
    "    intercepts = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "      indices = np.random.choice(inds, size=round(len(inds) * percentage))\n",
    "      slopes[i], intercepts[i] = np.polyfit(x[indices], y[indices], 1)\n",
    "\n",
    "    return slopes, intercepts\n",
    "\n",
    "\n",
    "  def confidenceInterval(array, confidenceLevel=1):\n",
    "    alphaValue = 1 - confidenceLevel\n",
    "    \n",
    "    halfAlphaValue = alphaValue / 2\n",
    "    \n",
    "    return np.percentile(array, [halfAlphaValue * 100, (1 - halfAlphaValue) * 100])\n",
    "\n",
    "\n",
    "  bootstrapSize = 1000\n",
    "  \n",
    "  xValues = np.array([0, bootstrapSize])\n",
    "  \n",
    "  bootstrapSlopes, bootstrapIntercepts = pairBootstrap(x, y, bootstrapSize, 0.95)\n",
    "\n",
    "  ci95 = confidenceInterval(bootstrapSlopes, 0.95)\n",
    "  print('The 95 percent confidence interval of the bootstraped', title, 'slopes is: ', ci95)\n",
    "\n",
    "  plt.hist(bootstrapSlopes, bins=30)\n",
    "  plt.axvline(ci95[0], color='red')\n",
    "  plt.axvline(ci95[1], color='red')\n",
    "\n",
    "  legendHandles = [\n",
    "    Line2D([0], [0], label='confidence interval', color='red'),\n",
    "    patches.Patch(color='C0', label='slope of bootstraped samples')\n",
    "  ]\n",
    "\n",
    "  plt.gcf().legend(handles=legendHandles, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=len(legendHandles))\n",
    "  plt.title('Probability density of the slopes of the bootstraped samples ' + title)\n",
    "  plt.tight_layout()\n",
    "  plt.ticklabel_format(useOffset=False, style='plain')\n",
    "  plt.margins(0.01)\n",
    "  plt.xlabel('Slopes from bootstraped samples')\n",
    "  plt.ylabel('Probability density function (PDF)')\n",
    "  plt.show()\n",
    "  \n",
    "  return (bootstrapSlopes, bootstrapIntercepts)\n",
    "\n",
    "bootstrapSlopes, bootstrapIntercepts = perform_bootstrapping(x, y, \"base clock difference\")\n",
    "bootstrapSlopes_boost, bootstrapIntercepts_boost = perform_bootstrapping(x, yboost, \"boost clock difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first one hundred bootstrap lines\n",
    "def plot_bootstrap_lines(x, y, bootstrapSlopes, bootstrapIntercepts, title=\"\"):\n",
    "  for i in range(100):\n",
    "    plt.plot(x, bootstrapSlopes[i] * x + bootstrapIntercepts[i], linewidth=0.4, alpha=0.2, color='red')\n",
    "\n",
    "  plt.plot(x, slope * x + intercept, linewidth=2, alpha=1, color='red')\n",
    "  plt.plot(x, y, marker='.', linestyle='none')\n",
    "\n",
    "  plt.xlabel('Year')\n",
    "  plt.ylabel('Total')\n",
    "  plt.title('Linear regression lines of one hundred bootstrap samples ' + title)\n",
    "  plt.show()\n",
    "\n",
    "plot_bootstrap_lines(x, y, bootstrapSlopes, bootstrapIntercepts, title=\"of base clock difference\")\n",
    "\n",
    "plot_bootstrap_lines(x, yboost, bootstrapSlopes_boost, bootstrapIntercepts_boost, title=\"of boost clock difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypthesis\n",
    "1. The amount of cores and the amount of threads coincide strongly\n",
    "2. The overclock speeds strongly coincide with the boost clock\n",
    "3. The newer the chip, the higher the achieved overclocked speeds\n",
    "4. Over time the difference between overclock speeds and boost clock speeds will decrease, maybe below the boost clock, given new aggressive boosts behaviours.\n",
    "5. The more cores a given CPU has, the lower its base clock speed is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearson correlation coefficient for all dataset points\n",
    "only_clockspeeds = overclock_data.drop([], axis=1)\n",
    "\n",
    "print(only_clockspeeds.corr(method=\"pearson\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearson correlation coefficient for all CPUs released in 2017 and later\n",
    "only_clockspeeds = overclock_data.drop([], axis=1)\n",
    "\n",
    "print(only_clockspeeds[only_clockspeeds[\"release\"] >= 2017].corr(method=\"pearson\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis evaluation\n",
    "\n",
    "Hypothesis 1: \"The amount of cores and the amount of threads coincide strongly\"<br>\n",
    "  As shown above, the pearson correlation coefficient between the amount of threads and the amount of cores is 0.948116 and 0.955526 for CPUs released in 2017 and later. Therefore the amount of cores and the amount of threads are strongly correlated and the hypothesis can be considered **true**.\n",
    "\n",
    "Hypothesis 2: \"The overclock speeds strongly coincide with the boost clock\"<br>\n",
    "  Both pearson correlations above, respectively show a strong and very strong pearson correlation coefficient between the achieved overclock speeds and the advertised boost clock speeds, at 0.592176 for all CPUs and 0.803467 for CPUs released in 2017 and later. Interrestingly, the pearson correlation coefficient suggests a stronger correlation between the overclocked clock speeds and the base clock speeds, rather than the boost clock speeds, when looking at all chips. Due to the high coefficients, the hypothesis can be considered **true**.\n",
    "\n",
    "Hypothesis 3: \"The newer the chip, the higher the achieved overclocked speeds\"<br>\n",
    "  The pearson correlation coefficient for all CPUs in the dataset for this relation is 0.310077, which indicates a light correlation between the two. Considering this coefficient the hypothesis can be considered **true**. For newer CPUs, released in 2017 and onwards, the correlation coefficient is even smaller at 0.163941, indicating a decrease over time. The coefficient for CPUs released in 2017 and later, in contrast to all CPUs, is too low and the hypothesis _in this case_ can be considered **false**.\n",
    "\n",
    "Hypothesis 4: \"Over time the difference between overclock speeds and boost clock speeds will decrease, maybe below the boost clock, given new aggressive boosts behaviours.\"<br>\n",
    "  Both pearson correlation coefficients have a negative value, -0.328864 for all CPUs and -0.193777 for CPUs released in 2017 and later.This indicates that the hypothesis can be considered **true** for all CPUs, the coefficient for CPUs released in 2017 and later can be considered **false**.\n",
    "\n",
    "Hypothesis 5: \"The more cores a given CPU has, the lower its base clock speed is\"<br>\n",
    "  The pearson correlation coefficient for all CPUs is 0.272317 and the hypothesis can, therefore, be considered **false**. In contrast to the coefficient for all CPUs, dating back to 2001, newer CPUs released in 2017 and later have a correlation coefficient of -0.202520 between the amount of cores and the base clock speed, suggesting that, for these CPUs, the hypothesis can be confirmed **true**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B tests cannot be performed on this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is the Bonferroni Test?\n",
    "\n",
    "The Bonferroni test is a type of multiple comparison test used in statistical analysis. When performing a hypothesis test with multiple comparisons, eventually a result could occur that appears to demonstrate statistical significance in the dependent variable, even when there is none.\n",
    "\n",
    "If a particular test, such as a linear regression, thus yields correct results 99% of the time, running the same regression on 100 different samples could lead to at least one false-positive result at some point. The Bonferroni test attempts to prevent data from incorrectly appearing to be statistically significant like this by making an adjustment during comparison testing.\n",
    "Key Takeaways\n",
    "\n",
    "The Bonferroni test is a statistical test used to reduce the instance of a false positive.\n",
    "In particular, Bonferroni designed an adjustment to prevent data from incorrectly appearing to be statistically significant.\n",
    "An important limitation of Bonferroni correction is that it may lead analysts to mix actual true results.\n",
    "\n",
    "Understanding the Bonferroni Test\n",
    "\n",
    "The Bonferroni test, also known as \"Bonferroni correction\" or \"Bonferroni adjustment\" suggests that the p-value for each test must be equal to its alpha divided by the number of tests performed.\n",
    "\n",
    "The Bonferroni test is a multiple-comparison correction used when several dependent or independent statistical tests are being performed simultaneously. The reason is that while a given alpha value may be appropriate for each individual comparison, it is not appropriate for the set of all comparisons. In order to eliminate multiple spurious positives, the alpha value needs to be lowered to account for the number of comparisons being performed.\n",
    "\n",
    "The test is named for the Italian mathematician who developed it, Carlo Emilio Bonferroni (1892–1960).1 Other types of multiple comparison tests include Scheffé's test and the Tukey-Kramer method test. A criticism of the Bonferroni test is that it is too conservative and may fail to catch some significant findings.\n",
    "\n",
    "In statistics, a null hypothesis is essentially the belief that there's no statistical difference between two data sets being compared. Hypothesis testing involves testing a statistical sample to confirm or reject a null hypothesis. The test is performed by taking a random sample of a population or group. While the null hypothesis is tested, the alternative hypothesis is also tested, whereby the two results are mutually exclusive. \n",
    "\n",
    "However, with any testing of a null hypothesis, there's the expectation that a false-positive result could occur. This is formally called a Type I error, and as a result, an error rate that reflects the likelihood of a Type I error is assigned to the test. In other words, a certain percentage of the results will likely yield a false positive.\n",
    "Using Bonferroni Correction\n",
    "\n",
    "For example, an error rate of 5% might typically be assigned to a statistical test, meaning that 5% of the time there will likely be a false positive. This 5% error rate is called the alpha level. However, when many comparisons are being made in an analysis, the error rate for each comparison can impact the other results, creating multiple false positives.\n",
    "\n",
    "Bonferroni designed his method of correcting for the increased error rates in hypothesis testing that had multiple comparisons. Bonferroni's adjustment is calculated by taking the number of tests and dividing it into the alpha value. Using the 5% error rate from our example, two tests would yield an error rate of 0.025 or (.05/2) while four tests would therefore have an error rate of .0125 or (.05/4). Notice that the error rate decreases as the sample size increases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
